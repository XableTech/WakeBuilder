# Acknowledgments

WakeBuilder builds upon the outstanding work of the open-source community.

---

## Core Technologies

### Audio Spectrogram Transformer (AST)

The foundation of WakeBuilder's few-shot learning capability.

- **Author**: Yuan Gong, MIT
- **Paper**: "AST: Audio Spectrogram Transformer"
- **Repository**: [github.com/YuanGongND/ast](https://github.com/YuanGongND/ast)
- **License**: MIT

### PyTorch

The deep learning framework powering all neural network operations.

- **Organization**: Meta AI
- **Repository**: [github.com/pytorch/pytorch](https://github.com/pytorch/pytorch)
- **License**: BSD-style

### Hugging Face Transformers

Provides the pre-trained AST model and easy model loading.

- **Organization**: Hugging Face
- **Repository**: [github.com/huggingface/transformers](https://github.com/huggingface/transformers)
- **License**: Apache 2.0

---

## TTS Engines

### Piper TTS

High-quality offline neural text-to-speech.

- **Author**: Michael Hansen (Rhasspy)
- **Repository**: [github.com/rhasspy/piper](https://github.com/rhasspy/piper)
- **License**: MIT

### Edge TTS

Access to Microsoft's neural TTS voices.

- **Author**: rany2
- **Repository**: [github.com/rany2/edge-tts](https://github.com/rany2/edge-tts)
- **License**: GPL-3.0

### Kokoro TTS

High-quality neural TTS with natural prosody.

- **Author**: hexgrad
- **Repository**: [github.com/hexgrad/kokoro](https://github.com/hexgrad/kokoro)
- **License**: Apache 2.0

### Coqui TTS

Multi-speaker TTS models including VCTK.

- **Organization**: Coqui AI
- **Repository**: [github.com/coqui-ai/TTS](https://github.com/coqui-ai/TTS)
- **License**: MPL 2.0

---

## Audio Processing

### librosa

Audio and music analysis library.

- **Authors**: Brian McFee et al.
- **Repository**: [github.com/librosa/librosa](https://github.com/librosa/librosa)
- **License**: ISC

### soundfile

Read and write audio files.

- **Repository**: [github.com/bastibe/python-soundfile](https://github.com/bastibe/python-soundfile)
- **License**: BSD-3-Clause

---

## Web Framework

### FastAPI

Modern, fast web framework for building APIs.

- **Author**: Sebasti√°n Ram√≠rez
- **Repository**: [github.com/tiangolo/fastapi](https://github.com/tiangolo/fastapi)
- **License**: MIT

### Uvicorn

Lightning-fast ASGI server.

- **Author**: Tom Christie
- **Repository**: [github.com/encode/uvicorn](https://github.com/encode/uvicorn)
- **License**: BSD-3-Clause

---

## Model Export

### ONNX

Open Neural Network Exchange format.

- **Organization**: ONNX Community
- **Repository**: [github.com/onnx/onnx](https://github.com/onnx/onnx)
- **License**: Apache 2.0

### ONNX Runtime

Cross-platform inference engine.

- **Organization**: Microsoft
- **Repository**: [github.com/microsoft/onnxruntime](https://github.com/microsoft/onnxruntime)
- **License**: MIT

---

## Documentation

### MkDocs Material

Beautiful documentation theme.

- **Author**: Martin Donath
- **Repository**: [github.com/squidfunk/mkdocs-material](https://github.com/squidfunk/mkdocs-material)
- **License**: MIT

---

## Datasets

### Speech Commands

The dataset used to pre-train the AST model.

- **Creator**: Google
- **Paper**: "Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition"

### UNAC (Universal Negative Audio Corpus)

Negative sample dataset for training.

- **Source**: Curated from various public domain audio sources

---

## Special Thanks

- The **Hugging Face** team for making state-of-the-art models accessible
- The **Rhasspy** community for Piper TTS and voice assistant tools
- Everyone who has contributed to the open-source ML ecosystem

---

<div align="center">
  <strong>Thank you to all the open-source contributors!</strong>
  <br><br>
  üéôÔ∏è ‚ù§Ô∏è üêç
</div>
