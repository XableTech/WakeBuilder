# WakeBuilder ğŸ™ï¸

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Status](https://img.shields.io/badge/status-alpha-orange.svg)]()

**WakeBuilder** is a comprehensive training platform that enables you to create custom wake word detection models entirely on your local machineâ€”no cloud services, no subscriptions, and no machine learning expertise required.

## ğŸŒŸ Features

- **ğŸ  100% Local Processing**: All training happens on your CPU. Your voice data never leaves your machine.
- **ğŸ¯ Simple Interface**: Web-based UI guides you through the entire process in minutes.
- **ğŸš€ Fast Training**: Create production-quality models in 5-15 minutes on typical hardware.
- **ğŸ”Š Few-Shot Learning**: Train effective models with just 3-5 voice recordings.
- **ğŸ¨ Sophisticated Augmentation**: Automatic generation of hundreds of training variations.
- **ğŸ³ Docker Ready**: One-command deployment with all dependencies included.
- **ğŸ†“ Open Source**: Apache 2.0 licensedâ€”use it for anything, commercial or personal.

## ğŸ¯ What is a Wake Word?

A wake word (like "Hey Siri" or "Alexa") is a special phrase that activates a voice assistant. WakeBuilder lets you create your own custom wake words like "Phoenix", "Hey Computer", or any phrase you choose.

## ğŸ—ï¸ Architecture

WakeBuilder uses a three-layer architecture:

1. **Pre-trained Base Model**: A speech understanding model that already knows what human speech sounds like across diverse speakers and accents.

2. **Wake Word Classifier**: A small neural network trained specifically for your custom wake word using transfer learning.

3. **Training Orchestration**: FastAPI backend that manages data augmentation, model training, evaluation, and real-time testing.

## ğŸ“‹ Prerequisites

- **Docker & Docker Compose** (recommended) OR
- **Python 3.12+** with `uv` package manager
- **8GB RAM** minimum (16GB recommended)
- **Multi-core CPU** (training will be faster)
- **Microphone** for recording wake word samples

## ğŸš€ Quick Start

### Using Docker (Recommended)

```bash
# Clone the repository
git clone https://github.com/yourusername/wakebuilder.git
cd wakebuilder

# Start WakeBuilder
docker-compose up

# Open your browser
# Navigate to http://localhost:8000
```

### Using Python & uv

```bash
# Clone the repository
git clone https://github.com/yourusername/wakebuilder.git
cd wakebuilder

# Create virtual environment and install dependencies
uv sync

# Activate the environment
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Run the application
uvicorn src.wakebuilder.backend.main:app --host 0.0.0.0 --port 8000

# Open your browser
# Navigate to http://localhost:8000
```

## ğŸ“– How to Use

### 1. Create a New Wake Word

1. Click **"Create New Wake Word"** on the home page
2. Enter your desired wake word (1-2 words, e.g., "Phoenix" or "Hey Computer")
3. Record 3-5 clear samples of yourself saying the wake word
4. Click **"Start Training"**

### 2. Wait for Training

Training typically takes 5-15 minutes. You'll see real-time progress updates:
- âœ… Generating synthetic voice variations
- âœ… Creating negative examples
- âœ… Training classifier network
- âœ… Evaluating model performance

### 3. Test Your Model

After training completes:
- Speak your wake word into the microphone
- Watch for visual feedback when detected
- Adjust sensitivity slider to fine-tune behavior
- Download the model for use with WakeEngine

## ğŸ—ï¸ Project Structure

```
WakeBuilder/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ wakebuilder/
â”‚       â”œâ”€â”€ training/          # Training pipeline and data augmentation
â”‚       â”œâ”€â”€ backend/            # FastAPI web server and API endpoints
â”‚       â””â”€â”€ frontend/           # Web UI (HTML, CSS, JavaScript)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ default/               # Pre-trained default wake words
â”‚   â””â”€â”€ custom/                # Your custom trained models
â”œâ”€â”€ data/
â”‚   â””â”€â”€ temp/                  # Temporary storage for recordings
â”œâ”€â”€ tts_voices/                # Piper TTS voice models
â”œâ”€â”€ tests/                     # Unit and integration tests
â”œâ”€â”€ project_spec/              # Project documentation
â”œâ”€â”€ pyproject.toml             # Project configuration and dependencies
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ Dockerfile                 # Docker image definition
â”œâ”€â”€ docker-compose.yml         # Docker deployment configuration
â””â”€â”€ README.md                  # This file
```

## ğŸ”§ Configuration

WakeBuilder can be configured via environment variables or the `config.py` file:

### Key Configuration Parameters

- **Audio Processing**: Sample rate (16kHz), mel spectrograms (80 bins)
- **Data Augmentation**: Speed variations, pitch shifts, noise levels
- **Training**: Learning rate (0.001), batch size (32), max epochs (50)
- **Model Architecture**: Embedding dim (512), hidden layers [256, 128]

See `src/wakebuilder/config.py` for all configurable parameters.

## ğŸ§ª Testing

```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=src/wakebuilder --cov-report=html

# Run specific test file
uv run pytest tests/test_training.py
```

## ğŸ› ï¸ Development

### Setting Up Development Environment

```bash
# Install with development dependencies
uv sync --group dev

# Run code formatting
uv run black src/
uv run ruff check src/ --fix

# Run type checking
uv run mypy src/
```

### Code Style

- **Formatter**: Black
- **Linter**: Ruff
- **Type Checker**: mypy
- **Docstrings**: Google style

## ğŸ“Š How It Works

### Training Pipeline

1. **User Input**: Record 3-5 samples of your wake word
2. **Data Augmentation**: Generate 500+ variations using:
   - Text-to-speech with multiple voices
   - Speed and pitch variations
   - Background noise injection
   - Volume randomization
3. **Negative Examples**: Create samples that should NOT trigger:
   - Phonetically similar words
   - Random speech
   - Silence and noise
4. **Feature Extraction**: Convert audio to embeddings using base model
5. **Classifier Training**: Train small neural network on embeddings
6. **Evaluation**: Test on validation set and calibrate threshold
7. **Model Export**: Save as ONNX format with metadata

### Why It Works with Few Samples

WakeBuilder uses **transfer learning**. The base model already understands speech patterns from thousands of hours of diverse audio. You're only teaching it to recognize ONE specific phrase pattern, not teaching it about speech from scratch.

## ğŸ¯ Default Wake Words

WakeBuilder ships with pre-trained models:

**Single Words**: Computer, Assistant, System, Listen, Voice

**Two Words**: Hey There, Wake Up, Hi Computer, Hi Assistant

These are ready to use immediately for testing and demonstrations.

## ğŸ“¦ Model Output

Each trained model produces:

1. **ONNX Model File** (`.onnx`): Neural network weights in open format
2. **Metadata File** (`.json`): Contains:
   - Wake word text
   - Creation timestamp
   - Recommended detection threshold
   - Performance metrics (accuracy, false positive/negative rates)

## ğŸ”’ Privacy & Security

- **No Cloud**: Everything runs locally on your machine
- **No Telemetry**: No data collection or phone-home features
- **Temporary Storage**: Voice recordings are deleted after training
- **Open Source**: Full transparencyâ€”audit the code yourself

## ğŸš§ Current Status

**Alpha Release** - Core functionality is implemented and working:

- âœ… Project structure and configuration
- âœ… Dependency management
- ğŸš§ Audio preprocessing pipeline (Phase 1)
- ğŸš§ Training pipeline (Phase 2)
- ğŸš§ FastAPI backend (Phase 3)
- ğŸš§ Web interface (Phase 4)
- ğŸš§ Docker deployment (Phase 5)
- ğŸš§ Testing and optimization (Phase 6)

## ğŸ—ºï¸ Roadmap

### Phase 1: Foundation (In Progress)
- [ ] Base speech embedding model integration
- [ ] Audio preprocessing pipeline
- [ ] Development environment setup

### Phase 2: Training Pipeline
- [ ] Data augmentation system
- [ ] Negative example generator
- [ ] Classifier training loop
- [ ] Model evaluation and threshold calibration

### Phase 3: Backend
- [ ] FastAPI endpoints
- [ ] Job management system
- [ ] WebSocket for real-time testing
- [ ] File storage and organization

### Phase 4: Frontend
- [ ] Home page and model dashboard
- [ ] Training wizard
- [ ] Progress tracking interface
- [ ] Real-time testing interface

### Phase 5: Deployment
- [ ] Dockerfile
- [ ] Docker Compose configuration
- [ ] Piper TTS integration
- [ ] Default model training

### Phase 6: Polish
- [ ] Comprehensive testing
- [ ] Performance optimization
- [ ] Documentation
- [ ] Example projects

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### Development Workflow

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Make your changes
4. Run tests and linting (`uv run pytest && uv run ruff check src/`)
5. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
6. Push to the branch (`git push origin feature/AmazingFeature`)
7. Open a Pull Request

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Piper TTS**: High-quality local text-to-speech
- **ONNX Runtime**: Efficient cross-platform inference
- **PyTorch**: Deep learning framework
- **FastAPI**: Modern web framework
- **librosa**: Audio processing library

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/wakebuilder/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/wakebuilder/discussions)
- **Documentation**: [Full Documentation](https://wakebuilder.readthedocs.io)

## ğŸŒŸ Related Projects

- **WakeEngine**: Companion library for real-time wake word detection
- **Piper TTS**: Local text-to-speech engine
- **ONNX**: Open Neural Network Exchange format

---

**Made with â¤ï¸ by the WakeBuilder Team**

*Democratizing wake word technology, one voice at a time.*
